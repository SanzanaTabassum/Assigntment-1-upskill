{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d0738666",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7a93646",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('train.csv')\n",
    "\n",
    "test = pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d90283ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 100000\n",
    "max_length = 220\n",
    "target_column = 'target'\n",
    "dimensionality = 300\n",
    "text_column = 'comment_text'\n",
    "val_fraction = 0.2\n",
    "n_components_list = [1, 2, 5]\n",
    "k_list = [1, 2, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85caf220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_val_data(x_train, y_train, val_fraction):\n",
    "    \n",
    "    x_train, y_train = joint_shuffle(x_train, y_train)\n",
    "    \n",
    "    val_size = int(val_fraction*x_train.shape[0])\n",
    "    \n",
    "    partial_x_train = x_train[val_size:]\n",
    "    \n",
    "    partial_y_train = y_train[val_size:]\n",
    "    \n",
    "    val_x_train = x_train[:val_size]\n",
    "    \n",
    "    val_y_train = y_train[:val_size]\n",
    "    \n",
    "    return partial_x_train, partial_y_train, val_x_train, val_y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1923a27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bow_prepare_data(train_data, test_data, text_column, target_column, vocab_size):\n",
    "    \n",
    "    raw_x_test = test_data[text_column].astype(str)\n",
    "    \n",
    "    raw_x_train = train_data[text_column].astype(str)\n",
    "    \n",
    "    y_train = train_data[target_column].values\n",
    "    \n",
    "    word_corpus = list(raw_x_test) + list(raw_x_train)\n",
    "    \n",
    "    vectorizer = CountVectorizer(strip_accents='ascii', max_features=vocab_size)\n",
    "\n",
    "    vectorizer.fit_transform(word_corpus)\n",
    "    \n",
    "    bow_x_test = vectorizer.transform(raw_x_test)\n",
    "    \n",
    "    bow_x_train = vectorizer.transform(raw_x_train)\n",
    "    \n",
    "    return bow_x_train, y_train, bow_x_test, vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ca29925",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def SVD(bow_x_train, bow_x_test, n_components):\n",
    "    \n",
    "    svd = TruncatedSVD(n_components=n_components).fit(bow_x_train)\n",
    "    \n",
    "    svd_train_data = svd.transform(bow_x_train)\n",
    "    \n",
    "    svd_test_data = svd.transform(bow_x_test)\n",
    "    \n",
    "    return svd_train_data, svd_test_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3cb189bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sgn(y):\n",
    "    \n",
    "    new_y = np.zeros(shape=y.shape)\n",
    "    \n",
    "    for i in range(len(y)):\n",
    "        \n",
    "        if y[i] >= 0.5:\n",
    "            \n",
    "            new_y[i] = 1\n",
    "            \n",
    "    return new_y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf477176",
   "metadata": {},
   "outputs": [],
   "source": [
    "def joint_shuffle(x_data, y_data):\n",
    "    \n",
    "    if x_data.shape[0] == y_data.shape[0]:\n",
    "    \n",
    "        p = np.random.permutation(x_data.shape[0])\n",
    "    \n",
    "    return x_data[p], y_data[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a75e8891",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_knn_val_test(x_train, y_train, x_test, y_test, n_components, k_list):\n",
    "    \n",
    "    class_y_train = sgn(y_train)\n",
    "    \n",
    "    class_y_test = sgn(y_test)\n",
    "    \n",
    "    svd_x_train, svd_x_test = SVD(x_train, x_test, n_components)\n",
    "    \n",
    "    training_auc = []\n",
    "    \n",
    "    val_auc = []\n",
    "    \n",
    "    for k in k_list:\n",
    "        \n",
    "        nbh = KNeighborsClassifier(n_neighbors=k)\n",
    "    \n",
    "        nbh.fit(svd_x_train, class_y_train)\n",
    "    \n",
    "        training_auc.append(metrics.roc_auc_score(class_y_train, nbh.predict(svd_x_train)))\n",
    "    \n",
    "        val_auc.append(metrics.roc_auc_score(class_y_test, nbh.predict(svd_x_test)))\n",
    "    \n",
    "    return training_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce00c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "def svd_knn_val(x_train, y_train, x_test, y_test, n_components_list, k_list):\n",
    "    \n",
    "    training_auc = np.zeros(shape=(len(n_components_list), len(k_list)))\n",
    "    \n",
    "    val_auc = np.zeros(shape=(len(n_components_list), len(k_list)))\n",
    "    \n",
    "    for i in range(len(n_components_list)):\n",
    "        \n",
    "        print(\"Performing validation on n_component =\", n_components_list[i])\n",
    "            \n",
    "        training_auc[i], val_auc[i] = svd_knn_val_test(x_train, \n",
    "                                                       y_train,\n",
    "                                                       x_test, \n",
    "                                                       y_test, \n",
    "                                                       n_components_list[i], \n",
    "                                                       k_list)\n",
    "    \n",
    "    return training_auc, val_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fee113d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def val_assess(val_auc, hyper_p_list_1, hyper_p_list_2):\n",
    "    \n",
    "    val_index = np.unravel_index(np.argmax(val_auc, axis=None), val_auc.shape)\n",
    "    \n",
    "    best_hyper_p_1 = hyper_p_list_1[val_index[0]]\n",
    "    \n",
    "    best_hyper_p_2 = hyper_p_list_2[val_index[1]]\n",
    "        \n",
    "    return best_hyper_p_1, best_hyper_p_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37e50255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_svd_knn(x_train, y_train, x_test, raw_test, best_n_component, best_k):\n",
    "    \n",
    "    class_y_train = sgn(y_train)\n",
    "    \n",
    "    svd_x_train, svd_x_test = SVD(x_train, x_test, best_n_component)\n",
    "    \n",
    "    nbh = KNeighborsClassifier(n_neighbors=best_k)\n",
    "    \n",
    "    nbh.fit(svd_x_train, class_y_train)\n",
    "    \n",
    "    predicted_y = nbh.predict(svd_x_test)\n",
    "    \n",
    "    submission = pd.DataFrame.from_dict({'id': raw_test.id, 'prediction': predicted_y})\n",
    "    \n",
    "    submission.to_csv('submission.csv', index=False)\n",
    "    \n",
    "    return submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "36cbe7f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bow_x_train, y_train, bow_x_test, vectorizer = bow_prepare_data(train, \n",
    "                                                                test, \n",
    "                                                                text_column, \n",
    "                                                                target_column, \n",
    "                                                                vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b3d7406c",
   "metadata": {},
   "outputs": [],
   "source": [
    "partial_x_train, partial_y_train, val_x_train, val_y_train = create_val_data(bow_x_train, \n",
    "                                                                             y_train, \n",
    "                                                                             val_fraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b970fb30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing validation on n_component = 1\n",
      "Performing validation on n_component = 2\n",
      "Performing validation on n_component = 5\n"
     ]
    }
   ],
   "source": [
    "training_auc, val_auc = svd_knn_val(partial_x_train, \n",
    "                                    partial_y_train, \n",
    "                                    val_x_train, \n",
    "                                    val_y_train, \n",
    "                                    n_components_list, \n",
    "                                    k_list)\n",
    "\n",
    "best_n_component, best_k = val_assess(val_auc, n_components_list, k_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8e881dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = predict_svd_knn(bow_x_train, y_train, bow_x_test, test, best_n_component, best_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f04c49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
